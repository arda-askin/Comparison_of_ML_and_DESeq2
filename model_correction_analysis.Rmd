---
title: "Model_Correction_Analysis"
output: html_document
date: "2025-01-12"
---

```{r}
library(dplyr)
library(caret)
library(MLeval)
library(pROC)
library(edgeR)
library(pROC)
library(randomForest)
library(glmnet)
library(xgboost)
```



# Data Set Prep.

```{r}
mel_dat <- readRDS("validation_lcpm.rds")
l_dat <- readRDS("skcm_ready.RDS")
l_dat$meta.multiple.bin <- factor(l_dat$meta.multiple.bin, levels = c("Low", "High"))
mel_dat$meta.multiple.bin <- factor(mel_dat$meta.multiple.bin, levels = c("Low", "High"))
l_dat <- l_dat %>% select(-meta.multiple.gene)
l_dat <- l_dat %>% select(intersect(colnames(l_dat), colnames(mel_dat)))
l_dat$meta.multiple.bin  <- as.numeric(l_dat$meta.multiple.bin) - 1
mel_dat$meta.multiple.bin  <- as.numeric(mel_dat$meta.multiple.bin) - 1
mel_dat <- mel_dat %>% select(intersect(colnames(l_dat), colnames(mel_dat)))
mel_dat$meta.multiple.bin <- factor(mel_dat$meta.multiple.bin, levels = c(0, 1))
l_te_2 <- mel_dat %>% select(-starts_with("meta."))

set_seeds <- c(12, 25, 37, 48, 124, 257, 478, 780, 1200, 2500)

cv_data_test <- list()
cv_c_data_test <- list()
cv_data_train <- list()
cv_c_data_train <- list()

for(i in 1:10){
  
  set.seed(set_seeds[i])
  trainIndex <- createDataPartition(l_dat$meta.multiple.bin, p = .7, 
                                  list = FALSE, 
                                  times = 1)
  
  train <- l_dat[ trainIndex,]
  test <- l_dat[-trainIndex,]
  l_tr <- train %>% select(-starts_with("meta."))
  l_te <- test %>% select(-starts_with("meta."))
  
  cv_data_test[[paste("cv",i, sep ="_")]] <- test
  cv_c_data_test[[paste("cv",i, sep ="_")]] <- l_te
  cv_data_train[[paste("cv",i, sep ="_")]] <- train
  cv_c_data_train[[paste("cv",i,sep = "_")]] <- l_tr
  
  
}

```

# Model Reading

```{r}
rf_manuel_models <-readRDS("rf_manuel_models.RDS")
glmnet_manuel_models <-readRDS("glmnet_manuel_models.RDS")
xgb_manuel_models <-readRDS("xgb_manuel_models.RDS")

```


#XGB Test

```{r}
accuracy_list <- list()

for (i in 1:10) {
xgb_preds <- predict(xgb_manuel_models[[i]], as.matrix(cv_c_data_test[[i]]))
xgb_class_preds <- as.data.frame(ifelse(xgb_preds > 0.5, 1, 0))
xgb_class_preds[,1] <- factor(xgb_class_preds[,1], levels = c(0, 1))
cv_data_test[[i]]$meta.multiple.bin  <- factor(cv_data_test[[i]]$meta.multiple.bin , levels = c(0, 1))
confusion <-confusionMatrix(factor(xgb_class_preds[,1]), factor(cv_data_test[[i]]$meta.multiple.bin))

accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    
accuracy_list[[paste("model",i, sep ="_")]] <- accuracy
  
}


accuracy_list

```

# XGB Valid

```{r}
val_accu_list <- list()

for (i in 1:10) {
  
xgb_preds <- predict(xgb_manuel_models[[i]], as.matrix(l_te_2))
xgb_class_preds <- as.data.frame(ifelse(xgb_preds > 0.5, 1, 0))
xgb_class_preds[,1] <- factor(xgb_class_preds[,1], levels = c(0, 1))

confusion <- confusionMatrix(xgb_class_preds[,1],mel_dat$meta.multiple.bin )
  
accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    

val_accu_list[[paste("model",i, sep ="_")]] <- accuracy
  
}    
    


val_accu_list
```

# RF Test

```{r}
accuracy_list <- list()

for (i in 1:10) {
  
rf_manual_predictions <- data.frame(p = predict(rf_manuel_models[[i]], cv_c_data_test[[i]]))
confusion <- confusionMatrix(rf_manual_predictions$p , as.factor(cv_data_test[[i]]$meta.multiple.bin))

accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    

accuracy_list[[paste("model",i, sep ="_")]] <- accuracy
  
}


accuracy_list

```

# RF Valid

```{r}
val_accu_list <- list()

for (i in 1:10) {
  
rf_manual_predictions <- data.frame(p = predict(rf_manuel_models[[i]], l_te_2))
confusion <- confusionMatrix(rf_manual_predictions$p , as.factor(mel_dat$meta.multiple.bin))

accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    

val_accu_list[[paste("model",i, sep ="_")]] <- accuracy
  
}    
    


val_accu_list
```

# GLMNET Test

```{r}
accuracy_list <- list()

for (i in 1:10) {
  
glmnet_preds <- predict(glmnet_manuel_models[[i]], as.matrix(cv_c_data_test[[i]]), 
  type = "response")
glmnet_class_preds <- as.data.frame(ifelse(glmnet_preds > 0.5, 1, 0))
glmnet_class_preds$s0 <- factor(glmnet_class_preds$s0, levels = c(0, 1))
cv_data_test[[i]]$meta.multiple.bin  <- factor(cv_data_test[[i]]$meta.multiple.bin , levels = c(0, 1))
confusion <- confusionMatrix(glmnet_class_preds$s0,cv_data_test[[i]]$meta.multiple.bin )
  
accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    

accuracy_list[[paste("model",i, sep ="_")]] <- accuracy
  
}


accuracy_list
```

# GLMNET Valid

```{r}
val_accu_list <- list()

for (i in 1:10) {
  
glmnet_preds <- predict(glmnet_manuel_models[[i]], as.matrix(l_te_2), 
  type = "response")
glmnet_class_preds <- as.data.frame(ifelse(glmnet_preds > 0.5, 1, 0))
glmnet_class_preds$s0 <- factor(glmnet_class_preds$s0, levels = c(0, 1))
confusion <- confusionMatrix(glmnet_class_preds$s0,mel_dat$meta.multiple.bin )
  
accuracy <- round(confusion$overall['Accuracy'], digits = 4)
    

val_accu_list[[paste("model",i, sep ="_")]] <- accuracy
  
}    
    
val_accu_list
```

