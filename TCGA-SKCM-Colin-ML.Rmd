---
title: "TCGA-BRCA-SIM-ML"
output: html_document
date: "2024-07-09"
---


```{r}
library(dplyr)
mel_dat <- readRDS("validation_lcpm.rds")

l_dat <- readRDS("skcm_ready.RDS")

l_dat$meta.multiple.bin <- factor(l_dat$meta.multiple.bin, levels = c("High", "Low"))

l_dat <- l_dat %>% select(-meta.multiple.gene)

l_dat <- l_dat %>% select(intersect(colnames(l_dat), colnames(mel_dat)))

mel_dat <- mel_dat %>% select(intersect(colnames(l_dat), colnames(mel_dat)))



```

```{r}

set.seed(23)

snr = 5

sd = mean(l_dat[["CXCL10"]])/snr

l_dat[["CXCL10_fpco"]]  <- l_dat[["CXCL10"]] + rnorm(length(l_dat[["CXCL10"]]), mean = 0, sd = sd) 

cor.test(l_dat[["CXCL10_fpco"]], l_dat[["CXCL10"]])
plot(l_dat[["CXCL10_fpco"]], l_dat[["CXCL10"]])

set.seed(23)

snr = 2

sd = mean(l_dat[["CXCL10"]])/snr

l_dat[["CXCL10_lpco"]] <-  l_dat[["CXCL10"]] + rnorm(length(l_dat[["CXCL10"]]), mean = 0, sd = sd) 

cor.test(l_dat[["CXCL10_lpco"]], l_dat[["CXCL10"]])
plot(l_dat[["CXCL10_lpco"]], l_dat[["CXCL10"]])

set.seed(23)

snr = 1

sd = mean(l_dat[["CXCL10"]])/snr

l_dat[["CXCL10_mpco"]] <-  l_dat[["CXCL10"]] + rnorm(length(l_dat[["CXCL10"]]), mean = 0, sd = sd) 

cor.test(l_dat[["CXCL10_mpco"]], l_dat[["CXCL10"]])
plot(l_dat[["CXCL10_mpco"]], l_dat[["CXCL10"]])

set.seed(23)

snr = 0.1

sd = mean(l_dat[["CXCL10"]])/snr

l_dat[["CXCL10_spco"]]  <-  l_dat[["CXCL10"]] + rnorm(length(l_dat[["CXCL10"]]), mean = 0, sd = sd) 

cor.test(l_dat[["CXCL10_spco"]] , l_dat[["CXCL10"]])
plot(l_dat[["CXCL10_spco"]] , l_dat[["CXCL10"]])

```




```{r}


# l_dat[["CXCL10"]]
# 
# l_dat[["CXCL10_copy"]] <- l_dat[["CXCL10"]]
# 
# set.seed(23)
# l_dat[["CXCL10_fco"]] <- l_dat[["CXCL10"]] + round(abs(rnorm(l_dat[["CXCL10"]], mean = mean(l_dat[["CXCL10"]]), sd = 1)))
# 
# cor.test(l_dat[["CXCL10_fco"]], l_dat[["CXCL10"]])
# plot(l_dat[["CXCL10_fco"]], l_dat[["CXCL10"]])
# 
# set.seed(23)
# l_dat[["CXCL10_lpco"]] <- l_dat[["CXCL10"]] + as.integer(abs(runif(l_dat[["CXCL10"]], min = (mean(l_dat[["CXCL10"]])- 3*sd(l_dat[["CXCL10"]])), max = (mean(l_dat[["CXCL10"]])- 1*sd(l_dat[["CXCL10"]])))))
# 
# cor.test(l_dat[["CXCL10_lpco"]], l_dat[["CXCL10"]])
# plot(l_dat[["CXCL10_lpco"]], l_dat[["CXCL10"]])
# 
# set.seed(23)
# l_dat[["CXCL10_mpco"]] <- l_dat[["CXCL10"]] + as.integer(abs(runif(l_dat[["CXCL10"]], min = (mean(l_dat[["CXCL10"]])- 5*sd(l_dat[["CXCL10"]])), max = (mean(l_dat[["CXCL10"]])- 1*sd(l_dat[["CXCL10"]])))))
# 
# cor.test(l_dat[["CXCL10_mpco"]], l_dat[["CXCL10"]])
# plot(l_dat[["CXCL10_mpco"]], l_dat[["CXCL10"]])
# 
# set.seed(23)
# l_dat[["CXCL10_spco"]] <- l_dat[["CXCL10"]] + as.integer(abs(runif(l_dat[["CXCL10"]], min = (mean(l_dat[["CXCL10"]])- 10*sd(l_dat[["CXCL10"]])), max = (mean(l_dat[["CXCL10"]])- 1*sd(l_dat[["CXCL10"]])))))
# 
# cor.test(l_dat[["CXCL10_spco"]], l_dat[["CXCL10"]])
# plot(l_dat[["CXCL10_spco"]], l_dat[["CXCL10"]])
# 
num <- nrow(l_dat)

library(dplyr)

set.seed(23)
l_dat_rn <- l_dat %>%  mutate(RG1 = round(abs(rnorm(n=num, mean=50, sd=10))),
                  RG2 = round(abs(rnorm(n=num, mean=500, sd=100))),
                  RG3 = round(abs(rnorm(n=num, mean=90, sd=2))),
                  RG4 = round(abs(runif(n=num, min = 500, max=1000))),
                  RG5 = round(abs(rnorm(n=num, mean=200, sd=100))),
                  RG6 = round(abs(rnorm(n=num, mean=350, sd=250))),
                  RG7 = round(abs(rnorm(n=num, mean=10, sd=2))),
                  RG8 = round(abs(runif(n=num, min = 1500, max = 3000))),
                  RG9 = round(abs(runif(n=num, min = 2000, max = 5000))),
                  RG10 = round(abs(runif(n=num, min = 0, max = 5)))
                  )

```


# for only colinearity

```{r}
library(caret)

set.seed(3456)

trainIndex <- createDataPartition(l_dat$meta.multiple.bin, p = .7, 
                                  list = FALSE, 
                                  times = 1)

train <- l_dat[ trainIndex,]

test <- l_dat[-trainIndex,]

summary(train$meta.multiple.bin)

summary(test$meta.multiple.bin)


l_tr <- train %>% select(-starts_with("meta."))
l_te <- test %>% select(-starts_with("meta."))
l_te_2 <- mel_dat %>% select(-starts_with("meta."))


```



# addition of random variables

```{r}
library(caret)

set.seed(3456)

trainIndex <- createDataPartition(l_dat_rn$meta.multiple.bin, p = .7, 
                                  list = FALSE, 
                                  times = 1)

train <- l_dat_rn[ trainIndex,]

test <- l_dat_rn[-trainIndex,]

summary(train$meta.multiple.bin)

summary(test$meta.multiple.bin)


l_tr <- train %>% select(-starts_with("meta."))
l_te <- test %>% select(-starts_with("meta."))
l_te_2 <- mel_dat %>% select(-starts_with("meta."))


```




```{r}
infg_gene_set <- c("RG1","RG2","RG3","RG4","RG5","RG6","RG7","RG8","RG9","RG10","CXCL10", "CXCL10_copy", "CXCL10_fco", "CXCL10_lpco", "CXCL10_mpco", "CXCL10_spco")


```



## xgboost model

```{r}
library(doParallel)

n_cores <- detectCores()
n_cores

# Register cluster
cluster <- makeCluster(n_cores - 1)
registerDoParallel(cluster)

# stopCluster(cl = cluster)

library(caret)

control <- trainControl(method='repeatedcv', 
                        number=10, 
                        # repeats=3, ## it can be used when performance is poor 
                        search = 'random',
                        savePredictions = TRUE, 
                        classProbs = TRUE, 
                        verboseIter = TRUE)

set.seed(50)

xgb_model = train(x = l_tr, 
              y = train$meta.multiple.bin, 
              method = "xgbTree", 
              trControl = control)



saveRDS(xgb_model, "rncolin_xgb_final.RDS")

# Model Performance 

# For Train Data Set 

library(MLeval)

x_XGB <- evalm(xgb_model)

data <- x_XGB$roc$data

library(pROC)

xgbImp <- varImp(xgb_model, scale = T)
xgbImp_d <- data.frame(xgbImp$importance)
# xgbImp_d <- xgbImp_d %>% filter(!Overall == 0)
plot(xgbImp, top = 20, )
xgbImp_d$gene <- rownames(xgbImp_d)
rownames(xgbImp_d) <- NULL
# xgbImp_d$order <- order(xgbImp_d$Overall, decreasing = T)
xgb_selected_gene_imp_inf <- xgbImp_d %>% filter(xgbImp_d$gene %in% infg_gene_set)

# For Test Data Set 

library(pROC)

xgb_roc <- roc(test$meta.multiple.bin, 
            predict(xgb_model, l_te, type = "prob")[,1], 
            levels = rev(levels(test$meta.multiple.bin)))

xgb_p <- plot(xgb_roc, print.auc=TRUE, 
     legacy.axes = TRUE)


# Confusion Matrix 

xgb_predicted = predict(xgb_model,l_te )

confusionMatrix(xgb_predicted, test$meta.multiple.bin)


```

## random forest model

```{r}
library(caret)

control <- trainControl(method='repeatedcv', 
                        number=10, 
                        # repeats=3,
                        search = 'random',
                        savePredictions = TRUE, 
                        classProbs = TRUE, 
                        verboseIter = TRUE)

set.seed(50)
rf_model <- train(x = l_tr, 
              y = train$meta.multiple.bin, 
                   method = 'rf',
                   metric = 'Accuracy',
                   # tuneLength  = 15, 
                   trControl = control)

# Model Performance 

# For Train

library(MLeval)

x <- evalm(rf_model)

rfImp <- varImp(rf_model, scale = T)
rfImp_d <- data.frame(rfImp$importance)
# rfImp_d <- rfImp_d %>% filter(!Overall == 0) %>% round(5)
plot(rfImp, top = 20, )
rfImp_d$gene <- rownames(rfImp_d)
rownames(rfImp_d) <- NULL
rfImp_d <- rfImp_d %>%  arrange(desc(Overall))
rfImp_d$order <- order(rfImp_d$Overall, decreasing = T)
rf_selected_gene_imp_inf <- rfImp_d %>% filter(rfImp_d$gene %in% infg_gene_set)


# For Test 

library(pROC)

rf_roc <- roc(test$meta.multiple.bin, 
            predict(rf_model, l_te, type = "prob")[,1], 
            levels = rev(levels(test$meta.multiple.bin)))
rf_roc

plot(rf_roc, print.auc=TRUE, 
     legacy.axes = TRUE)

# Confusion Matrix 

rf_predicted = predict(rf_model, l_te)

confusionMatrix(rf_predicted, test$meta.multiple.bin)


saveRDS(rf_model, "rncolin_rf_final.RDS")


```


# SVM Model

```{r}
library(caret)


control <- trainControl(method='repeatedcv', 
                        number=10, 
                        # repeats=3,
                        search = 'random',
                        savePredictions = TRUE, 
                        classProbs = TRUE, 
                        verboseIter = TRUE)

set.seed(50)
svmRadialWeights_model <- train(x = l_tr, 
              y = train$meta.multiple.bin, 
                   method = 'svmRadialWeights',
                   metric = 'Accuracy',
                   # tuneLength  = 15,
                   trControl = control)

library(MLeval)

x_svm <- evalm(svmRadialWeights_model)


svmImp <- varImp(svmRadialWeights_model, scale = T)
svmImp_d <- data.frame(svmImp$importance)
svmImp_d <- svmImp_d %>% filter(!(High == 0 & Low == 0))
svmImp_d$genes <- rownames(svmImp_d)
plot(svmImp, top = 20)
svmImp_d$gene <- rownames(svmImp_d)
rownames(svmImp_d) <- NULL
svmImp_d <- svmImp_d %>%  arrange(desc(High))
svmImp_d$order <- order(svmImp_d$High, decreasing = T)
svm_selected_gene_imp_inf <- svmImp_d %>% filter(svmImp_d$gene %in% infg_gene_set)

saveRDS(svmRadialWeights_model, "rncolin_svm.rds")


svm_predicted = predict(svmRadialWeights_model, l_te)

confusionMatrix(svm_predicted, test$meta.multiple.bin)

library(pROC)

svm_roc <- roc(test$meta.multiple.bin, 
            predict(svmRadialWeights_model, l_te, type = "prob")[,1], 
            levels = rev(levels(test$meta.multiple.bin)))
svm_roc

plot(svm_roc, print.auc=TRUE, 
     legacy.axes = TRUE)

```

# GLMNET Model

```{r}
library(caret)


control <- trainControl(method='repeatedcv', 
                        number=10, 
                        # repeats=3,
                        search = 'random',
                        savePredictions = TRUE, 
                        classProbs = TRUE, 
                        verboseIter = TRUE)

set.seed(50)
glmnet_model <- train(x = l_tr, 
              y = train$meta.multiple.bin,
                   method = 'glmnet',
                   metric = 'Accuracy',
                   family = "binomial",
                   # tuneLength  = 15,
                   trControl = control)

library(MLeval)

x_glmnet <- evalm(glmnet_model)


glmnetImp <- varImp(glmnet_model, scale = T)
glmnetImp_d <- data.frame(glmnetImp$importance)
# glmnetImp_d <- glmnetImp_d %>% filter(!Overall == 0)
plot(glmnetImp, top = 20)
glmnetImp_d$gene <- rownames(glmnetImp_d)
rownames(glmnetImp_d) <- NULL
glmnetImp_d <- glmnetImp_d%>%  arrange(desc(Overall))
glmnetImp_d$order <- order(glmnetImp_d$Overall, decreasing = T)
glmnet_selected_gene_imp_inf <- glmnetImp_d %>% filter(glmnetImp_d$gene %in% infg_gene_set)

glmnet_predicted = predict(glmnet_model, l_te)
confusionMatrix(glmnet_predicted, test$meta.multiple.bin)

library(pROC)

glmnet_roc <- roc(test$meta.multiple.bin, 
            predict(glmnet_model, l_te, type = "prob")[,1], 
            levels = rev(levels(test$meta.multiple.bin)))
glmnet_roc

plot(glmnet_roc, print.auc=TRUE, 
     legacy.axes = TRUE)

saveRDS(glmnet_model, "rncolin_glmnet_final.rds")

coefs <- coef(glmnet_model$finalModel, glmnet_model$finalModel$lambdaOpt)
coefs_df <- as.data.frame(as.matrix(coefs))
coefs_df <- coefs_df %>% filter(s1 != 0)
coefs_df$variable <- rownames(coefs_df)
coefs_df<- coefs_df %>% filter(variable != "(Intercept)")
plot(glmnetImp_d$Overall, coefs_df$s1,xlab = "importance score", ylab = "coefficients", main = "GLMNET Importance Score vs	Coefficients")


```

```{r}

library(h2o)

h2o.init(nthreads = -1) 

train.hex <- as.h2o(train)
test.hex <- as.h2o(test)

```


```{r}

hyper_params <- list(
                     activation = c("Rectifier", "Maxout", "Tanh", "RectifierWithDropout", "MaxoutWithDropout", "TanhWithDropout"), 
                     hidden = list(c(5, 5, 5, 5, 5), c(10, 10, 10, 10), c(50, 50, 50), c(100, 100, 100)),
                     epochs = c(50, 100, 200),
                     l1 = c(0, 0.00001, 0.0001), 
                     l2 = c(0, 0.00001, 0.0001),
                     rate = c(0, 01, 0.005, 0.001),
                     rate_annealing = c(1e-8, 1e-7, 1e-6),
                     rho = c(0.9, 0.95, 0.99, 0.999),
                     epsilon = c(1e-10, 1e-8, 1e-6, 1e-4),
                     momentum_start = c(0, 0.5),
                     momentum_stable = c(0.99, 0.5, 0),
                     input_dropout_ratio = c(0, 0.1, 0.2),
                     max_w2 = c(10, 100, 1000, 3.4028235e+38)
                     )



search_criteria <- list(strategy = "RandomDiscrete", 
                        max_models = 100,
                        max_runtime_secs = 900,
                        stopping_tolerance = 0.001,
                        stopping_rounds = 15,
                        seed = 42)

 y = grep("meta.multiple.bin", colnames(train))
  
 x = 1:(y-1)
 
 dl_grid_co <- h2o.grid(algorithm = "deeplearning", 
                    x = x,
                    y = y,
                    # weights_column = weights,
                    grid_id = "dl_grid_co",
                    training_frame = train.hex,
                    validation_frame = test.hex,
                    nfolds = 10,                           
                    fold_assignment = "Stratified",
                    hyper_params = hyper_params,
                    search_criteria = search_criteria,
                    seed = 42
                    ,keep_cross_validation_predictions=TRUE
                    ,keep_cross_validation_fold_assignment=TRUE
                    ,variable_importances = T
                    )

 

  gridperf_co <- h2o.getGrid(grid_id = "dl_grid_co",
                             sort_by = "auc",
                             decreasing = TRUE)
 
  print(gridperf2)
  summary(gridperf2)
  
  best_ann <- h2o.getModel(gridperf_co@model_ids[[1]])
  
  h2o.saveModel(best_ann,"rncolin_ann_fmod.rds")
 
  #"C:\\TCGA_SKCM_model\\rncolin_ann_fmod.rds\\dl_grid_co_model_4"
  
  varimp <- h2o.varimp(best_ann)
  
  varimp_d <- as.data.frame(varimp)
  
  
  perf2 <- h2o.performance(best_ann, valid = TRUE)
 
  plot(perf2, type = "roc")
  
  source("h2o_imp_var.R")
  
  h2o_imp_var(best_ann)
 
  
a <-as.data.frame(predict(best_ann, test.hex))
  
table(test$meta.multiple.bin, a$predict)
```
